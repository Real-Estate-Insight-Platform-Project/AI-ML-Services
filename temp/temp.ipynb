{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceca7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "from get_bq_data import get_bq_data\n",
    "from model_trainer_1 import get_predictions\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS' ] = 'service_keys.json'\n",
    "\n",
    "client = bigquery. Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e827056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data():\n",
    "    \"\"\"Load dataset, aggregate, and push to Supabase\"\"\" \n",
    "\n",
    "    existing_data = get_bq_data(client,\"state_market\") \n",
    "\n",
    "    return existing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcff5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>state_num</th>\n",
       "      <th>median_listing_price</th>\n",
       "      <th>median_listing_price_mm</th>\n",
       "      <th>median_listing_price_yy</th>\n",
       "      <th>active_listing_count</th>\n",
       "      <th>active_listing_count_mm</th>\n",
       "      <th>active_listing_count_yy</th>\n",
       "      <th>median_days_on_market</th>\n",
       "      <th>...</th>\n",
       "      <th>median_square_feet_yy</th>\n",
       "      <th>average_listing_price</th>\n",
       "      <th>average_listing_price_mm</th>\n",
       "      <th>average_listing_price_yy</th>\n",
       "      <th>total_listing_count</th>\n",
       "      <th>total_listing_count_mm</th>\n",
       "      <th>total_listing_count_yy</th>\n",
       "      <th>pending_ratio</th>\n",
       "      <th>pending_ratio_mm</th>\n",
       "      <th>pending_ratio_yy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>198060</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>26519</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>-0.1296</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>264342</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>28563</td>\n",
       "      <td>-0.004288</td>\n",
       "      <td>-0.1169</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>-0.067376</td>\n",
       "      <td>0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>279375</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>3710</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>327328</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>3710</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>312000</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>26807</td>\n",
       "      <td>-0.026015</td>\n",
       "      <td>-0.1148</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>477781</td>\n",
       "      <td>-0.029825</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>34886</td>\n",
       "      <td>-0.034965</td>\n",
       "      <td>-0.0948</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>-0.048711</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>169900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>15717</td>\n",
       "      <td>-0.013309</td>\n",
       "      <td>-0.1057</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>235007</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>18446</td>\n",
       "      <td>-0.013161</td>\n",
       "      <td>-0.0939</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>549000</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>71686</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>-0.1431</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>1030673</td>\n",
       "      <td>-0.016759</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>106530</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>-0.1262</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>-0.069627</td>\n",
       "      <td>0.0314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>21543</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>639805</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>31820</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.2011</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>-0.011600</td>\n",
       "      <td>-0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>648900</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>24463</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>887686</td>\n",
       "      <td>-0.012300</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>33936</td>\n",
       "      <td>-0.010900</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.3888</td>\n",
       "      <td>-0.011200</td>\n",
       "      <td>-0.1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>261500</td>\n",
       "      <td>-0.027900</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>4245</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>325854</td>\n",
       "      <td>-0.029700</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>6712</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>-0.010600</td>\n",
       "      <td>-0.0729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>392325</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>13190</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>506718</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>18863</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>-0.049800</td>\n",
       "      <td>-0.0216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>472500</td>\n",
       "      <td>-0.040600</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>2833</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>1194779</td>\n",
       "      <td>-0.031400</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>3414</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>-0.0233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5049 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  state_num  median_listing_price  median_listing_price_mm  \\\n",
       "0     2017      7          1                198060                -0.004223   \n",
       "1     2017      7          2                279375                -0.006667   \n",
       "2     2017      7          3                312000                -0.018868   \n",
       "3     2017      7          4                169900                 0.000000   \n",
       "4     2017      7          5                549000                -0.001637   \n",
       "...    ...    ...        ...                   ...                      ...   \n",
       "5044  2025      9         47                450000                 0.000000   \n",
       "5045  2025      9         48                648900                -0.001600   \n",
       "5046  2025      9         49                261500                -0.027900   \n",
       "5047  2025      9         50                392325                -0.016700   \n",
       "5048  2025      9         51                472500                -0.040600   \n",
       "\n",
       "      median_listing_price_yy  active_listing_count  active_listing_count_mm  \\\n",
       "0                      0.0654                 26519                 0.002343   \n",
       "1                     -0.0333                  3710                 0.092784   \n",
       "2                      0.0576                 26807                -0.026015   \n",
       "3                      0.0534                 15717                -0.013309   \n",
       "4                      0.0660                 71686                 0.037319   \n",
       "...                       ...                   ...                      ...   \n",
       "5044                   0.0228                 21543                 0.028400   \n",
       "5045                  -0.0016                 24463                -0.002500   \n",
       "5046                   0.0898                  4245                 0.038700   \n",
       "5047                   0.0257                 13190                 0.037400   \n",
       "5048                  -0.0151                  2833                -0.019700   \n",
       "\n",
       "      active_listing_count_yy  median_days_on_market  ...  \\\n",
       "0                     -0.1296                     75  ...   \n",
       "1                     -0.0196                     53  ...   \n",
       "2                     -0.1148                     56  ...   \n",
       "3                     -0.1057                     73  ...   \n",
       "4                     -0.1431                     40  ...   \n",
       "...                       ...                    ...  ...   \n",
       "5044                   0.2931                     45  ...   \n",
       "5045                   0.2562                     57  ...   \n",
       "5046                   0.1546                     52  ...   \n",
       "5047                   0.0899                     44  ...   \n",
       "5048                   0.1312                     69  ...   \n",
       "\n",
       "      median_square_feet_yy  average_listing_price  average_listing_price_mm  \\\n",
       "0                    0.0233                 264342                 -0.000707   \n",
       "1                   -0.0278                 327328                 -0.003374   \n",
       "2                    0.0086                 477781                 -0.029825   \n",
       "3                    0.0245                 235007                  0.003810   \n",
       "4                   -0.0005                1030673                 -0.016759   \n",
       "...                     ...                    ...                       ...   \n",
       "5044                 0.0005                 639805                  0.012100   \n",
       "5045                -0.0035                 887686                 -0.012300   \n",
       "5046                 0.0120                 325854                 -0.029700   \n",
       "5047                -0.0036                 506718                 -0.004000   \n",
       "5048                -0.0101                1194779                 -0.031400   \n",
       "\n",
       "      average_listing_price_yy  total_listing_count  total_listing_count_mm  \\\n",
       "0                       0.0543                28563               -0.004288   \n",
       "1                      -0.0121                 3710                0.092784   \n",
       "2                       0.0699                34886               -0.034965   \n",
       "3                       0.0652                18446               -0.013161   \n",
       "4                       0.1016               106530                0.009907   \n",
       "...                        ...                  ...                     ...   \n",
       "5044                    0.0062                31820                0.022700   \n",
       "5045                   -0.0109                33936               -0.010900   \n",
       "5046                    0.0233                 6712                0.030100   \n",
       "5047                    0.0422                18863                0.000800   \n",
       "5048                    0.0381                 3414               -0.001800   \n",
       "\n",
       "      total_listing_count_yy  pending_ratio  pending_ratio_mm  \\\n",
       "0                    -0.1169         0.0789         -0.067376   \n",
       "1                    -0.0196         0.0000          0.000000   \n",
       "2                    -0.0948         0.2988         -0.048711   \n",
       "3                    -0.0939         0.1771          0.002831   \n",
       "4                    -0.1262         0.4944         -0.069627   \n",
       "...                      ...            ...               ...   \n",
       "5044                  0.2011         0.4810         -0.011600   \n",
       "5045                  0.1543         0.3888         -0.011200   \n",
       "5046                  0.1029         0.5822         -0.010600   \n",
       "5047                  0.0766         0.4327         -0.049800   \n",
       "5048                  0.1068         0.2077          0.013300   \n",
       "\n",
       "      pending_ratio_yy  \n",
       "0               0.0179  \n",
       "1               0.0000  \n",
       "2               0.0294  \n",
       "3               0.0145  \n",
       "4               0.0314  \n",
       "...                ...  \n",
       "5044           -0.1128  \n",
       "5045           -0.1228  \n",
       "5046           -0.0729  \n",
       "5047           -0.0216  \n",
       "5048           -0.0233  \n",
       "\n",
       "[5049 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = aggregate_data()\n",
    "df.sort_values(by=['year', 'month', 'state_num'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7dbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_2 import preprocess_data_2\n",
    "\n",
    "target_df = preprocess_data_2(25, df.copy())\n",
    "prediction_df = target_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ecf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, prediction_df):\n",
    "    \"\"\"Load dataset, train model, save predictions to Supabase\"\"\"\n",
    "\n",
    "    features = [\n",
    "        \"median_listing_price\",\n",
    "        \"median_days_on_market\"\n",
    "    ]\n",
    "    \n",
    "    for feature in features:\n",
    "        predictions = get_predictions(df, feature, 24)\n",
    "        prediction_df[feature] = predictions\n",
    "\n",
    "    for col in features:\n",
    "        if col in prediction_df.columns:\n",
    "            prediction_df[col] = prediction_df[col].astype(int)\n",
    "\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbbe098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory: 1.80 MB\n",
      "Final memory: 1.20 MB\n",
      "Reduced by 33.2%\n",
      "Validation RMSE: 25758.3877, RMSLE: 0.0576, MAE: 20027.8076, MAPE: 4.53%, R²: 0.9684\n",
      "Validation RMSE: 24591.6228, RMSLE: 0.0579, MAE: 19875.8159, MAPE: 4.63%, R²: 0.9707\n",
      "Validation RMSE: 24912.9814, RMSLE: 0.0585, MAE: 20113.1023, MAPE: 4.70%, R²: 0.9691\n",
      "Validation RMSE: 23030.3157, RMSLE: 0.0582, MAE: 19681.4635, MAPE: 4.81%, R²: 0.9735\n",
      "Validation RMSE: 21073.4184, RMSLE: 0.0485, MAE: 16258.8128, MAPE: 3.77%, R²: 0.9783\n",
      "Validation RMSE: 37272.8521, RMSLE: 0.0910, MAE: 31277.6786, MAPE: 7.34%, R²: 0.9331\n",
      "Validation RMSE: 48528.4525, RMSLE: 0.1063, MAE: 39186.1468, MAPE: 8.77%, R²: 0.8870\n",
      "Validation RMSE: 60313.0797, RMSLE: 0.1443, MAE: 53695.0836, MAPE: 12.08%, R²: 0.8332\n",
      "Validation RMSE: 77465.1050, RMSLE: 0.1804, MAE: 69075.0726, MAPE: 15.23%, R²: 0.7142\n",
      "Validation RMSE: 91817.1577, RMSLE: 0.2163, MAE: 81119.1544, MAPE: 17.78%, R²: 0.5991\n",
      "Validation RMSE: 59468.9872, RMSLE: 0.1317, MAE: 51184.2574, MAPE: 11.10%, R²: 0.8245\n",
      "Validation RMSE: 64754.6291, RMSLE: 0.1393, MAE: 54609.3480, MAPE: 11.71%, R²: 0.7927\n",
      "Validation RMSE: 87566.4345, RMSLE: 0.2029, MAE: 76891.7693, MAPE: 17.04%, R²: 0.6176\n",
      "Validation RMSE: 52216.6100, RMSLE: 0.1197, MAE: 44851.1060, MAPE: 10.25%, R²: 0.8595\n",
      "Validation RMSE: 56253.0437, RMSLE: 0.1369, MAE: 44981.7889, MAPE: 10.47%, R²: 0.8279\n",
      "Validation RMSE: 49708.1017, RMSLE: 0.1170, MAE: 39353.9347, MAPE: 9.17%, R²: 0.8648\n",
      "Validation RMSE: 50653.2442, RMSLE: 0.1124, MAE: 41833.1884, MAPE: 9.22%, R²: 0.8648\n",
      "Validation RMSE: 53861.0929, RMSLE: 0.1245, MAE: 45223.1875, MAPE: 10.29%, R²: 0.8543\n",
      "Validation RMSE: 89353.5477, RMSLE: 0.2302, MAE: 80325.5080, MAPE: 18.50%, R²: 0.6003\n",
      "Validation RMSE: 87893.5708, RMSLE: 0.2188, MAE: 79525.2065, MAPE: 17.95%, R²: 0.6206\n",
      "Validation RMSE: 79899.9807, RMSLE: 0.1981, MAE: 72056.7785, MAPE: 16.28%, R²: 0.6788\n",
      "Validation RMSE: 75047.4221, RMSLE: 0.1854, MAE: 63515.9687, MAPE: 14.45%, R²: 0.7089\n",
      "Validation RMSE: 74452.1828, RMSLE: 0.1841, MAE: 64184.9133, MAPE: 14.74%, R²: 0.6979\n",
      "Validation RMSE: 70015.6830, RMSLE: 0.1706, MAE: 60362.7387, MAPE: 13.87%, R²: 0.7336\n",
      "🏃 View run XGB_Darts_Model_median_listing_price at: http://127.0.0.1:5000/#/experiments/1/runs/9d3c7de0a64a49afa35146885aeb42cf\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.380794\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.389910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.399229\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.409683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.422354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.437655\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.456196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.477270\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.497987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.516342\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.533878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.549332\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.562691\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.574619\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.585905\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.597963\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.611756\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.628131\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.646538\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.666218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.685533\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.702961\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.717503\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 162754\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.730016\n",
      "Validation RMSE: 12832.7438, RMSLE: 0.0288, MAE: 9167.2924, MAPE: 2.13%, R²: 0.9922\n",
      "Validation RMSE: 27372.0374, RMSLE: 0.0667, MAE: 21422.7442, MAPE: 5.11%, R²: 0.9637\n",
      "Validation RMSE: 27919.2680, RMSLE: 0.0692, MAE: 22581.7007, MAPE: 5.46%, R²: 0.9611\n",
      "Validation RMSE: 33631.5733, RMSLE: 0.0838, MAE: 27900.1229, MAPE: 6.77%, R²: 0.9435\n",
      "Validation RMSE: 34065.0555, RMSLE: 0.0863, MAE: 28616.1109, MAPE: 6.95%, R²: 0.9433\n",
      "Validation RMSE: 43539.3443, RMSLE: 0.1056, MAE: 36131.7101, MAPE: 8.46%, R²: 0.9086\n",
      "Validation RMSE: 39753.6119, RMSLE: 0.0960, MAE: 33120.2046, MAPE: 7.71%, R²: 0.9241\n",
      "Validation RMSE: 52315.8949, RMSLE: 0.1196, MAE: 46129.4516, MAPE: 10.25%, R²: 0.8745\n",
      "Validation RMSE: 77152.9680, RMSLE: 0.1845, MAE: 70193.7393, MAPE: 15.74%, R²: 0.7165\n",
      "Validation RMSE: 81334.0436, RMSLE: 0.1967, MAE: 73929.9320, MAPE: 16.60%, R²: 0.6854\n",
      "Validation RMSE: 75608.3170, RMSLE: 0.1776, MAE: 68706.7768, MAPE: 15.33%, R²: 0.7164\n",
      "Validation RMSE: 88524.8962, RMSLE: 0.2065, MAE: 79447.3705, MAPE: 17.63%, R²: 0.6126\n",
      "Validation RMSE: 82153.2325, RMSLE: 0.1955, MAE: 73969.3213, MAPE: 16.67%, R²: 0.6635\n",
      "Validation RMSE: 53158.4403, RMSLE: 0.1272, MAE: 46480.6674, MAPE: 10.85%, R²: 0.8544\n",
      "Validation RMSE: 54994.2854, RMSLE: 0.1305, MAE: 46067.7100, MAPE: 10.67%, R²: 0.8355\n",
      "Validation RMSE: 52505.4616, RMSLE: 0.1229, MAE: 42943.4156, MAPE: 9.83%, R²: 0.8491\n",
      "Validation RMSE: 55381.0310, RMSLE: 0.1264, MAE: 45747.1286, MAPE: 10.25%, R²: 0.8384\n",
      "Validation RMSE: 60754.2783, RMSLE: 0.1386, MAE: 50612.8380, MAPE: 11.36%, R²: 0.8147\n",
      "Validation RMSE: 78170.3968, RMSLE: 0.1939, MAE: 68461.2347, MAPE: 15.66%, R²: 0.6941\n",
      "Validation RMSE: 87849.8666, RMSLE: 0.2147, MAE: 79192.8283, MAPE: 17.73%, R²: 0.6209\n",
      "Validation RMSE: 83262.4470, RMSLE: 0.2027, MAE: 73829.2970, MAPE: 16.56%, R²: 0.6512\n",
      "Validation RMSE: 75494.9254, RMSLE: 0.1869, MAE: 65008.0959, MAPE: 14.88%, R²: 0.7054\n",
      "Validation RMSE: 70816.2873, RMSLE: 0.1744, MAE: 61642.1594, MAPE: 14.18%, R²: 0.7267\n",
      "Validation RMSE: 67508.0353, RMSLE: 0.1656, MAE: 58973.5938, MAPE: 13.65%, R²: 0.7524\n",
      "🏃 View run LightGBM_Darts_Model_median_listing_price at: http://127.0.0.1:5000/#/experiments/1/runs/0f2ad62cc3f14fe6bfa33918eae80512\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "Using LightGBM model for predictions\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.561769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.572509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.582925\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.593560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.604684\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.616716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.629950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.644003\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.657168\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.669063\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.680377\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.690578\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.699494\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.707474\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.714796\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.722223\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.730307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.739603\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.749945\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.760864\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.771413\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.780834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.788638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164529\n",
      "[LightGBM] [Info] Number of data points in the train set: 2652, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.795352\n",
      "Initial memory: 1.80 MB\n",
      "Final memory: 1.20 MB\n",
      "Reduced by 33.2%\n",
      "Validation RMSE: 3.1589, RMSLE: 0.0638, MAE: 2.4273, MAPE: 5.02%, R²: 0.8791\n",
      "Validation RMSE: 6.3269, RMSLE: 0.1114, MAE: 5.1235, MAPE: 9.79%, R²: 0.5448\n",
      "Validation RMSE: 9.4267, RMSLE: 0.1498, MAE: 7.2555, MAPE: 10.87%, R²: 0.0808\n",
      "Validation RMSE: 11.8374, RMSLE: 0.1700, MAE: 9.2549, MAPE: 12.35%, R²: -0.2248\n",
      "Validation RMSE: 14.1609, RMSLE: 0.2399, MAE: 11.3577, MAPE: 17.01%, R²: 0.0982\n",
      "Validation RMSE: 6.1034, RMSLE: 0.1318, MAE: 4.4707, MAPE: 9.24%, R²: 0.6616\n",
      "Validation RMSE: 6.5124, RMSLE: 0.1423, MAE: 5.3595, MAPE: 12.43%, R²: 0.5135\n",
      "Validation RMSE: 7.0536, RMSLE: 0.1703, MAE: 5.3619, MAPE: 12.35%, R²: 0.4578\n",
      "Validation RMSE: 7.7414, RMSLE: 0.1761, MAE: 5.6497, MAPE: 12.57%, R²: 0.2789\n",
      "Validation RMSE: 8.3113, RMSLE: 0.1929, MAE: 6.4129, MAPE: 13.13%, R²: 0.1328\n",
      "Validation RMSE: 9.9619, RMSLE: 0.2047, MAE: 7.7887, MAPE: 14.55%, R²: -0.0839\n",
      "Validation RMSE: 14.1024, RMSLE: 0.2887, MAE: 11.0492, MAPE: 19.27%, R²: -0.7707\n",
      "Validation RMSE: 14.0598, RMSLE: 0.2663, MAE: 11.3278, MAPE: 19.13%, R²: -0.4694\n",
      "Validation RMSE: 13.0749, RMSLE: 0.2245, MAE: 10.6856, MAPE: 16.53%, R²: -0.3519\n",
      "Validation RMSE: 11.2288, RMSLE: 0.1639, MAE: 9.1325, MAPE: 12.61%, R²: -0.0421\n",
      "Validation RMSE: 13.5302, RMSLE: 0.1886, MAE: 11.6010, MAPE: 14.82%, R²: -0.3188\n",
      "Validation RMSE: 19.3216, RMSLE: 0.2928, MAE: 15.5323, MAPE: 21.21%, R²: -0.4183\n",
      "Validation RMSE: 13.7791, RMSLE: 0.2814, MAE: 11.5186, MAPE: 20.87%, R²: -0.0579\n",
      "Validation RMSE: 14.6868, RMSLE: 0.3569, MAE: 11.9568, MAPE: 23.83%, R²: -0.8422\n",
      "Validation RMSE: 15.9612, RMSLE: 0.3991, MAE: 12.9856, MAPE: 26.47%, R²: -1.4246\n",
      "Validation RMSE: 14.0125, RMSLE: 0.2939, MAE: 10.9472, MAPE: 20.28%, R²: -0.6781\n",
      "Validation RMSE: 15.8774, RMSLE: 0.3158, MAE: 12.6997, MAPE: 21.92%, R²: -1.1102\n",
      "Validation RMSE: 16.7062, RMSLE: 0.3097, MAE: 13.5813, MAPE: 22.15%, R²: -1.2170\n",
      "Validation RMSE: 19.2877, RMSLE: 0.3638, MAE: 15.7992, MAPE: 24.75%, R²: -1.5006\n",
      "🏃 View run XGB_Darts_Model_median_days_on_market at: http://127.0.0.1:5000/#/experiments/1/runs/fa7a0a4bc13b4a6aa465f78b2c3abcdf\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.538262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.533512\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.531969\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.531928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.521530\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.501035\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.472060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.439296\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.411856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.396629\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.385763\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.375931\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.369908\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.370559\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.379196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.391989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.400610\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.399537\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.390019\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.375371\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.365814\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.365779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.372056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166805\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 662\n",
      "[LightGBM] [Info] Start training from score 0.381950\n",
      "Validation RMSE: 2.5545, RMSLE: 0.0495, MAE: 2.0494, MAPE: 4.19%, R²: 0.9210\n",
      "Validation RMSE: 7.0692, RMSLE: 0.1231, MAE: 5.4086, MAPE: 10.23%, R²: 0.4317\n",
      "Validation RMSE: 7.5154, RMSLE: 0.1217, MAE: 5.6401, MAPE: 8.69%, R²: 0.4158\n",
      "Validation RMSE: 9.9412, RMSLE: 0.1456, MAE: 7.6518, MAPE: 10.34%, R²: 0.1362\n",
      "Validation RMSE: 12.4851, RMSLE: 0.2081, MAE: 10.2012, MAPE: 15.40%, R²: 0.2990\n",
      "Validation RMSE: 6.7812, RMSLE: 0.1482, MAE: 5.3141, MAPE: 10.71%, R²: 0.5822\n",
      "Validation RMSE: 6.6824, RMSLE: 0.1396, MAE: 5.6135, MAPE: 12.51%, R²: 0.4878\n",
      "Validation RMSE: 5.7236, RMSLE: 0.1369, MAE: 4.1603, MAPE: 9.82%, R²: 0.6430\n",
      "Validation RMSE: 6.8202, RMSLE: 0.1621, MAE: 4.6090, MAPE: 10.34%, R²: 0.4403\n",
      "Validation RMSE: 8.7457, RMSLE: 0.2018, MAE: 6.9600, MAPE: 14.28%, R²: 0.0398\n",
      "Validation RMSE: 10.4123, RMSLE: 0.2210, MAE: 8.0337, MAPE: 15.09%, R²: -0.1842\n",
      "Validation RMSE: 13.6482, RMSLE: 0.2720, MAE: 10.7987, MAPE: 18.86%, R²: -0.6585\n",
      "Validation RMSE: 13.8396, RMSLE: 0.2601, MAE: 11.0623, MAPE: 18.62%, R²: -0.4238\n",
      "Validation RMSE: 10.8068, RMSLE: 0.1802, MAE: 8.9289, MAPE: 13.94%, R²: 0.0765\n",
      "Validation RMSE: 10.6494, RMSLE: 0.1530, MAE: 8.8257, MAPE: 12.29%, R²: 0.0627\n",
      "Validation RMSE: 12.3667, RMSLE: 0.1718, MAE: 10.5683, MAPE: 13.69%, R²: -0.1017\n",
      "Validation RMSE: 16.7055, RMSLE: 0.2539, MAE: 14.1286, MAPE: 19.91%, R²: -0.0602\n",
      "Validation RMSE: 15.9260, RMSLE: 0.3372, MAE: 13.0266, MAPE: 23.65%, R²: -0.4132\n",
      "Validation RMSE: 15.7298, RMSLE: 0.3847, MAE: 13.0377, MAPE: 26.04%, R²: -1.1131\n",
      "Validation RMSE: 15.1365, RMSLE: 0.3586, MAE: 12.2373, MAPE: 24.45%, R²: -1.1806\n",
      "Validation RMSE: 14.6667, RMSLE: 0.3119, MAE: 11.4984, MAPE: 21.27%, R²: -0.8385\n",
      "Validation RMSE: 17.6390, RMSLE: 0.3645, MAE: 14.3182, MAPE: 24.88%, R²: -1.6044\n",
      "Validation RMSE: 20.4173, RMSLE: 0.4039, MAE: 17.1090, MAPE: 28.13%, R²: -2.3114\n",
      "Validation RMSE: 19.8177, RMSLE: 0.3724, MAE: 16.4242, MAPE: 25.84%, R²: -1.6399\n",
      "🏃 View run LightGBM_Darts_Model_median_days_on_market at: http://127.0.0.1:5000/#/experiments/1/runs/f84113ad9585437288bd9cd78754c66e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "Using XGBoost model for predictions\n"
     ]
    }
   ],
   "source": [
    "preds = train_model(df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffed54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2ff08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acac6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_df = df.groupby(\"state_num\").tail(1).reset_index(drop=True)\n",
    "preds['year_month'] = (preds['year'] - 2025) * 12 + preds['month'] - 9\n",
    "preds.drop(columns=['year', 'month'], inplace=True)\n",
    "cols_order = ['year_month', 'state_num', 'median_listing_price', 'median_days_on_market']\n",
    "preds = preds[cols_order]\n",
    "preds = preds[preds['year_month'].isin([3,6,12])]\n",
    "preds.loc[preds['year_month'] == 12, 'median_listing_price'] = preds.loc[preds['year_month'] == 12, 'median_listing_price'] * 1.15\n",
    "preds.loc[preds['year_month'] == 6, 'median_listing_price'] = preds.loc[preds['year_month'] == 6, 'median_listing_price'] * 1.1\n",
    "\n",
    "preds['appreciation'] = 0.0\n",
    "for index, row in preds.iterrows():\n",
    "    state_num = row['state_num']\n",
    "    \n",
    "    current_price = latest_df[(latest_df['state_num'] == state_num)]['median_listing_price'].values[0]\n",
    "    predicted_price = row['median_listing_price']\n",
    "    \n",
    "    appreciation = ((predicted_price - current_price) / current_price) * 100\n",
    "    preds.loc[index, 'appreciation'] = appreciation\n",
    "\n",
    "def calculate_volatility(df):\n",
    "    volatility = {}\n",
    "    for state in df['state_num'].unique():\n",
    "        state_data = df[df['state_num'] == state].sort_values(by=['year', 'month'])\n",
    "        if len(state_data) >= 12:\n",
    "            last_12_mm = state_data['median_listing_price_mm'].tail(12).values\n",
    "            volatility[state] = np.std(last_12_mm) * 100\n",
    "        else:\n",
    "            volatility[state] = np.nan  # Not enough data to calculate volatility\n",
    "    return volatility\n",
    "\n",
    "volatility_data = calculate_volatility(df)\n",
    "\n",
    "preds['volatility'] = 0.0  # Initialize Volatility column\n",
    "\n",
    "for index, row in preds.iterrows():\n",
    "    state_num = row['state_num']\n",
    "    if state_num in volatility_data:\n",
    "        preds.loc[index, 'volatility'] = volatility_data[state_num]\n",
    "    else:\n",
    "        preds.loc[index, 'volatility'] = np.nan\n",
    "\n",
    "def normalize_days_on_market(preds):\n",
    "    inv_days = preds.groupby('year_month')['median_days_on_market'].transform(\n",
    "        lambda s: np.where(s != 0, 1 / s, 1)\n",
    "    )\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    preds = preds.copy()\n",
    "    preds['liquidity'] = scaler.fit_transform(inv_days.to_frame()) * 100\n",
    "    return preds\n",
    "\n",
    "preds = normalize_days_on_market(preds)\n",
    "preds.drop(columns=['median_listing_price', 'median_days_on_market'], inplace=True)\n",
    "preds['IOI'] = (0.4 * preds['appreciation']) + (0.3 * preds['liquidity']) - (0.3 * preds['volatility'])\n",
    "preds['IOI'] = preds.groupby('year_month')['IOI'].transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "preds['IOI'] = preds['IOI'] * 100\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bead767",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv(\"state_investment_insights.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
