{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e60087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer, Scaler, InvertibleMapper\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from darts.models import RegressionModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d412e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9a919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"data/State_Processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c139b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 0. Setup DataFrame ------------------------------------------------\n",
    "# df is your DataFrame with columns: 'year','month','state', 'median_listing_price', ...others...\n",
    "# Ensure month/day produce a proper date (use first of month)\n",
    "df = new_df.copy()\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str).str.zfill(2) + '-01')\n",
    "# sort\n",
    "df = df.sort_values(['state','date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976afdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['state_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd9332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 1. Create per-state TimeSeries ----------------------------------\n",
    "# We'll build a dict: one grouped TimeSeries object per state (Darts supports grouping)\n",
    "grouped_ts = {}\n",
    "grouped_static = {}   # optional static covariates per state\n",
    "\n",
    "for state, g in df.groupby('state'):\n",
    "    # create a TimeSeries with monthly frequency\n",
    "    ts = TimeSeries.from_dataframe(\n",
    "    g,\n",
    "    time_col=\"date\",\n",
    "    value_cols=\"median_listing_price\",\n",
    "    freq=\"MS\",\n",
    "    )\n",
    "    grouped_ts[state] = ts\n",
    "    \n",
    "    # optionally create a small static vector for the state (if columns exist)\n",
    "    # use first row of the group for static features\n",
    "    # static_cols = ['Region', 'Division']  # example static columns — adapt to your df\n",
    "    # static_row = g[static_cols].iloc[0].to_dict()\n",
    "    # grouped_static[state] = static_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a119c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 2. Create past and/or future covariates --------------------------\n",
    "# Choose covariates you consider useful and that exist per (state, month)\n",
    "# Example: use active_listing_count and pending_ratio as past covariates (monthly history)\n",
    "past_cov_ts = {}\n",
    "future_cov_ts = {}\n",
    "past_cov_cols = ['median_listing_price_mm',\n",
    "    'median_listing_price_yy', 'active_listing_count',\n",
    "    'active_listing_count_mm', 'active_listing_count_yy',\n",
    "    'median_days_on_market', 'median_days_on_market_mm',\n",
    "    'median_days_on_market_yy', 'new_listing_count', 'new_listing_count_mm',\n",
    "    'new_listing_count_yy', 'price_increased_count',\n",
    "    'price_increased_count_mm', 'price_increased_count_yy',\n",
    "    'price_increased_share', 'price_increased_share_mm',\n",
    "    'price_increased_share_yy', 'price_reduced_count',\n",
    "    'price_reduced_count_mm', 'price_reduced_count_yy',\n",
    "    'price_reduced_share', 'price_reduced_share_mm',\n",
    "    'price_reduced_share_yy', 'pending_listing_count',\n",
    "    'pending_listing_count_mm', 'pending_listing_count_yy',\n",
    "    'median_listing_price_per_square_foot',\n",
    "    'median_listing_price_per_square_foot_mm',\n",
    "    'median_listing_price_per_square_foot_yy', 'median_square_feet',\n",
    "    'median_square_feet_mm', 'median_square_feet_yy',\n",
    "    'average_listing_price', 'average_listing_price_mm',\n",
    "    'average_listing_price_yy', 'total_listing_count',\n",
    "    'total_listing_count_mm', 'total_listing_count_yy', 'pending_ratio',\n",
    "    'pending_ratio_mm', 'pending_ratio_yy']\n",
    "future_cov_cols = ['month','year']  # calendar features known ahead\n",
    "\n",
    "for state, g in df.groupby('state'):\n",
    "    # Past covariates as a multivariate TimeSeries\n",
    "    if all(c in g.columns for c in past_cov_cols):\n",
    "        past_cov_ts[state] = TimeSeries.from_dataframe(g, time_col='date', value_cols=past_cov_cols, freq='MS')\n",
    "    else:\n",
    "        past_cov_ts[state] = None\n",
    "\n",
    "    if all(c in g.columns for c in future_cov_cols):\n",
    "        future_cov_ts[state] = TimeSeries.from_dataframe(g, time_col='date', value_cols=future_cov_cols, freq='MS')\n",
    "    else:\n",
    "        future_cov_ts[state] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ce6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 3. Build and fit preprocessing pipeline (per-state or global) ----\n",
    "# We'll use a per-state pipeline (keeps scaling per-state) or reuse one global pipeline if preferred.\n",
    "pipeline_dict = {}\n",
    "ts_transformed = {}\n",
    "\n",
    "for state in grouped_ts:\n",
    "    log_transformer = InvertibleMapper(np.log1p, np.expm1)   # log1p for target, invertible\n",
    "    scaler = Scaler()\n",
    "    pipe = Pipeline([log_transformer, scaler])\n",
    "    # fit_transform expects a TimeSeries (or list); we pass the one series\n",
    "    transformed = pipe.fit_transform(grouped_ts[state])\n",
    "    pipeline_dict[state] = pipe\n",
    "    ts_transformed[state] = transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f041d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 4. Prepare for training: create dictionaries for Darts model -------\n",
    "# Darts LightGBMModel can be fit on a list (or sequence) of series; collect them\n",
    "series_list = [ts_transformed[s] for s in ts_transformed]\n",
    "past_cov_list = [past_cov_ts[s] for s in ts_transformed]\n",
    "future_cov_list = [future_cov_ts[s] for s in ts_transformed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394aa171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 5. Train/validation split ---------------------------------------\n",
    "# Example: hold out the last month for validation for each state\n",
    "# We'll do a simple split: train on all but last month, validate on last month\n",
    "n_predict = 1  # next month\n",
    "train_series = []\n",
    "val_series = []\n",
    "train_pasts = []\n",
    "val_pasts = []\n",
    "train_futures = []\n",
    "val_futures = []\n",
    "test_futures = []\n",
    "\n",
    "for s in ts_transformed:\n",
    "    ts = ts_transformed[s]\n",
    "    # if len(ts) < 24:\n",
    "    #     # skip too-short series (optional) or handle differently\n",
    "    #     continue\n",
    "    train = ts[:-n_predict]\n",
    "    val = ts[-n_predict:]  # last month\n",
    "    train_series.append(train)\n",
    "    val_series.append(val)\n",
    "    # same slicing for covariates if present\n",
    "    if past_cov_ts[s] is not None:\n",
    "        train_pasts.append(past_cov_ts[s][:-n_predict])\n",
    "        val_pasts.append(past_cov_ts[s][-n_predict:])\n",
    "    else:\n",
    "        train_pasts.append(None)\n",
    "        val_pasts.append(None)\n",
    "    if future_cov_ts[s] is not None:\n",
    "        train_futures.append(future_cov_ts[s][:-n_predict])\n",
    "        val_futures.append(future_cov_ts[s][-n_predict:])\n",
    "        test_futures.append(future_cov_ts[s])  # for final test prediction\n",
    "    else:\n",
    "        train_futures.append(None)\n",
    "        val_futures.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bf6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- 6. Instantiate and fit LightGBMModel -----------------------------\n",
    "# # Choose lags in months (e.g., last 12 months)\n",
    "# lags = 12\n",
    "# lags_past_covariates = list(range(-12,0))   # previous 12 months of past covariates\n",
    "# lags_future_covariates = list(range(1, n_predict+1))  # months ahead (just 1)\n",
    "\n",
    "# extra_model = RegressionModel(\n",
    "#     lags=lags,\n",
    "#     lags_past_covariates=lags_past_covariates,\n",
    "#     lags_future_covariates=lags_future_covariates,\n",
    "#     model=ExtraTreesRegressor(n_estimators=1000, random_state=42),\n",
    "#     output_chunk_length=n_predict\n",
    "# )\n",
    "\n",
    "# # Fit on the training series list (global model trained across all states)\n",
    "# extra_model.fit(series=train_series, past_covariates=train_pasts, future_covariates=train_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2954c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import BlockRNNModel\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler, InvertibleMapper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bf4b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# detect GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    # use one GPU (change devices to -1 or a list to use more)\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": 1, \"auto_select_gpus\": True}\n",
    "else:\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"cpu\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54127dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 18.2 K | train\n",
      "6 | fc              | Sequential       | 33     | train\n",
      "-------------------------------------------------------------\n",
      "18.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.2 K    Total params\n",
      "0.073     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\1 Disk D\\Mora Academic\\Sem 5\\Data Science and Engineering Project\\AI-ML-Services\\myenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f86cd1d62b48848a5ed8b35fe7fecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlockRNNModel(output_chunk_shift=0, model=LSTM, hidden_dim=32, n_rnn_layers=2, hidden_fc_sizes=None, dropout=0.1, activation=ReLU, input_chunk_length=12, output_chunk_length=1, optimizer_kwargs={'lr': 0.001}, pl_trainer_kwargs={'accelerator': 'cpu'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_chunk_length = 12   # use the past 12 months\n",
    "output_chunk_length = 1   # predict 1 month ahead\n",
    "n_epochs = 100            # training epochs\n",
    "hidden_dim = 32           # size of LSTM hidden units\n",
    "n_rnn_layers = 2          # number of stacked LSTM layers\n",
    "dropout = 0.1             # dropout for regularization\n",
    "model_type = \"LSTM\"       # could also be \"GRU\" or \"RNN\"\n",
    "\n",
    "# Instantiate model\n",
    "block_rnn = BlockRNNModel(\n",
    "    input_chunk_length = input_chunk_length,\n",
    "    output_chunk_length = output_chunk_length,\n",
    "    model = model_type,\n",
    "    hidden_dim = hidden_dim,\n",
    "    n_rnn_layers = n_rnn_layers,\n",
    "    dropout = dropout,\n",
    "    # Optional: output_chunk_shift if you want to leave a gap so the model doesn't peek right up to the target\n",
    "    output_chunk_shift = 0,\n",
    "    # Loss function, optimizer, etc.\n",
    "    optimizer_kwargs = {\"lr\": 1e-3},\n",
    "    # Use GPU if available\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs  \n",
    ")\n",
    "\n",
    "# Fit model on training set (list of states)\n",
    "block_rnn.fit(\n",
    "    series = train_series, \n",
    "    past_covariates = train_pasts, \n",
    "    verbose = True,\n",
    "    epochs = n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6723c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5de084f5472460685f3f2af01129af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict 1 month ahead for validation\n",
    "preds = block_rnn.predict(\n",
    "    n = 1,\n",
    "    series = train_series,\n",
    "    past_covariates = train_pasts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "# Extend each state's future covariates separately\n",
    "for i, ts in enumerate(test_futures):\n",
    "    if ts is None:\n",
    "        continue\n",
    "    last_date = ts.end_time()\n",
    "    future_ext = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=n_predict, freq=\"MS\")\n",
    "    \n",
    "    extra_covs = pd.DataFrame({\n",
    "        \"year\": future_ext.year,\n",
    "        \"month\": future_ext.month,\n",
    "    }, index=future_ext)\n",
    "    \n",
    "    extra_covs_ts = TimeSeries.from_dataframe(extra_covs)\n",
    "    test_futures[i] = ts.append(extra_covs_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec67fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 7. Validate (predict the held-out month) -------------------------\n",
    "# preds = extra_model.predict(\n",
    "#     n=n_predict,\n",
    "#     series=train_series,\n",
    "#     past_covariates=train_pasts,\n",
    "#     future_covariates=test_futures  # includes July covariates\n",
    "# )\n",
    "# preds is a list/sequence of TimeSeries (one per input series)\n",
    "# invert transforms per state and compute metrics\n",
    "import pandas as pd\n",
    "y_true = []\n",
    "y_hat = []\n",
    "\n",
    "for i, sname in enumerate(ts_transformed):\n",
    "    # preds[i] corresponds to series_list order; be careful with alignment\n",
    "    pred_ts = preds[i]\n",
    "    # invert transform using the state's pipeline\n",
    "    inv = pipeline_dict[sname].inverse_transform(pred_ts)\n",
    "    # extract scalar value\n",
    "    y_hat.append(inv.values()[-1].item())   # predicted next-month price\n",
    "    # true next-month value (from val_series)\n",
    "    true_val = val_series[i]\n",
    "    true_inv = pipeline_dict[sname].inverse_transform(true_val)\n",
    "    y_true.append(true_inv.values()[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "699786d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 88059.3393, RMSLE: 0.2097, MAE: 80310.0417, MAPE: 17.84%, R²: 0.5991\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_hat = np.array(y_hat)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_true, y_hat))\n",
    "rmsle = math.sqrt(((np.log1p(np.maximum(0, y_hat)) - np.log1p(np.maximum(0, y_true)))**2).mean())\n",
    "mae = mean_absolute_error(y_true, y_hat)\n",
    "mape = np.mean(np.abs((y_true - y_hat) / y_true)) * 100\n",
    "r2 = r2_score(y_true, y_hat)\n",
    "\n",
    "print(f\"Validation RMSE: {rmse:.4f}, RMSLE: {rmsle:.4f}, \"\n",
    "      f\"MAE: {mae:.4f}, MAPE: {mape:.2f}%, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d32432",
   "metadata": {},
   "source": [
    "# Predictions on AUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 5. Train/validation split ---------------------------------------\n",
    "# Example: hold out the last month for validation for each state\n",
    "# We'll do a simple split: train on all but last month, validate on last month\n",
    "\n",
    "train_series = []\n",
    "train_pasts = []\n",
    "train_futures = []\n",
    "test_futures = []\n",
    "\n",
    "for s in ts_transformed:\n",
    "    ts = ts_transformed[s]\n",
    "    train = ts\n",
    "    train_series.append(train)\n",
    "    # same slicing for covariates if present\n",
    "    if past_cov_ts[s] is not None:\n",
    "        train_pasts.append(past_cov_ts[s])\n",
    "    else:\n",
    "        train_pasts.append(None)\n",
    "    if future_cov_ts[s] is not None:\n",
    "        train_futures.append(future_cov_ts[s])\n",
    "        test_futures.append(future_cov_ts[s])\n",
    "    else:\n",
    "        train_futures.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: `RegressionModel` is deprecated and will be removed in a future version. Use `SKLearnModel` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RegressionModel(lags=12, lags_past_covariates=[-12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1], lags_future_covariates=[1], output_chunk_length=1, output_chunk_shift=0, add_encoders=None, model=ExtraTreesRegressor(n_estimators=1000, random_state=42), multi_models=True, use_static_covariates=True, random_state=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------- 6. Instantiate and fit LightGBMModel -----------------------------\n",
    "# Choose lags in months (e.g., last 12 months)\n",
    "lags = 12\n",
    "lags_past_covariates = list(range(-12,0))   # previous 12 months of past covariates\n",
    "lags_future_covariates = list(range(1, n_predict+1))  # months ahead (just 1)\n",
    "\n",
    "extra_model = RegressionModel(\n",
    "    lags=lags,\n",
    "    lags_past_covariates=lags_past_covariates,\n",
    "    lags_future_covariates=lags_future_covariates,\n",
    "    model=ExtraTreesRegressor(n_estimators=1000, random_state=42),\n",
    "    output_chunk_length=n_predict\n",
    ")\n",
    "\n",
    "# Fit on the training series list (global model trained across all states)\n",
    "extra_model.fit(series=train_series, past_covariates=train_pasts, future_covariates=train_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "# Extend each state's future covariates separately\n",
    "for i, ts in enumerate(test_futures):\n",
    "    if ts is None:\n",
    "        continue\n",
    "    last_date = ts.end_time()\n",
    "    future_ext = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=n_predict, freq=\"MS\")\n",
    "    \n",
    "    extra_covs = pd.DataFrame({\n",
    "        \"year\": future_ext.year,\n",
    "        \"month\": future_ext.month,\n",
    "    }, index=future_ext)\n",
    "    \n",
    "    extra_covs_ts = TimeSeries.from_dataframe(extra_covs)\n",
    "    test_futures[i] = ts.append(extra_covs_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "# Extend each state's future covariates separately\n",
    "for i, ts in enumerate(test_futures):\n",
    "    if ts is None:\n",
    "        continue\n",
    "    last_date = ts.end_time()\n",
    "    future_ext = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=n_predict, freq=\"MS\")\n",
    "    \n",
    "    extra_covs = pd.DataFrame({\n",
    "        \"year\": future_ext.year,\n",
    "        \"month\": future_ext.month,\n",
    "    }, index=future_ext)\n",
    "    \n",
    "    extra_covs_ts = TimeSeries.from_dataframe(extra_covs)\n",
    "    test_futures[i] = ts.append(extra_covs_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb47463",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real = pd.read_csv(\"data\\RDC_Inventory_Core_Metrics_State.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real = test_real.sort_values(['state']).reset_index(drop=True)\n",
    "test_real = test_real['median_listing_price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfee4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- 7. Validate (predict the held-out month) -------------------------\n",
    "preds = extra_model.predict(\n",
    "    n=n_predict,\n",
    "    series=train_series,\n",
    "    past_covariates=train_pasts,\n",
    "    future_covariates=test_futures  # includes July covariates\n",
    ")\n",
    "# preds is a list/sequence of TimeSeries (one per input series)\n",
    "# invert transforms per state and compute metrics\n",
    "import pandas as pd\n",
    "y_true = []\n",
    "y_hat = []\n",
    "\n",
    "for i, sname in enumerate(ts_transformed):\n",
    "    # preds[i] corresponds to series_list order; be careful with alignment\n",
    "    pred_ts = preds[i]\n",
    "    # invert transform using the state's pipeline\n",
    "    inv = pipeline_dict[sname].inverse_transform(pred_ts)\n",
    "    # extract scalar value\n",
    "    y_hat.append(inv.values()[-1].item())   # predicted next-month price\n",
    "    # true next-month value (from val_series)\n",
    "    true_val = val_series[i]\n",
    "    true_inv = pipeline_dict[sname].inverse_transform(true_val)\n",
    "    y_true.append(true_inv.values()[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a2a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 7012.6984, RMSLE: 0.0139, MAE: 4831.6669, MAPE: 1.06%, R²: 0.9973\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_true = np.array(test_real)\n",
    "y_hat = np.array(y_hat)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_true, y_hat))\n",
    "rmsle = math.sqrt(((np.log1p(np.maximum(0, y_hat)) - np.log1p(np.maximum(0, y_true)))**2).mean())\n",
    "mae = mean_absolute_error(y_true, y_hat)\n",
    "mape = np.mean(np.abs((y_true - y_hat) / y_true)) * 100\n",
    "r2 = r2_score(y_true, y_hat)\n",
    "\n",
    "print(f\"Validation RMSE: {rmse:.4f}, RMSLE: {rmsle:.4f}, \"\n",
    "      f\"MAE: {mae:.4f}, MAPE: {mape:.2f}%, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1ef23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea37ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668846d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f2311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
