{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "95e60087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer, Scaler, InvertibleMapper\n",
    "from darts.models import XGBModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "baa47f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_root():\n",
    "    return Path().resolve().parent.parent\n",
    "\n",
    "# set mlflow tracking uri\n",
    "mlflow.set_tracking_uri(uri=(get_project_root() / 'AI-ML-Services' / 'forecasting_engine' / 'mlruns').as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b3e34db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id = mlflow.create_experiment(\"RealEstate_Price_Prediction\", tags={\n",
    "#     \"topic\":\"experiment-management\",\n",
    "#     \"version\": \"v1\"\n",
    "# })\n",
    "\n",
    "# print(f\"Experiment created with ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "56a6ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the experiment to the one we created earlier.\n",
    "experiment = mlflow.set_experiment(experiment_name=\"RealEstate_Price_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d412e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cb9a919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"data/State_Processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "17c139b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str).str.zfill(2) + '-01')\n",
    "# sort\n",
    "df = df.sort_values(['state','date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "976afdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['state_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0dd9332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ts = {}\n",
    "grouped_static = {}   # optional static covariates per state\n",
    "\n",
    "for state, g in df.groupby('state'):\n",
    "    # create a TimeSeries with monthly frequency\n",
    "    ts = TimeSeries.from_dataframe(\n",
    "    g,\n",
    "    time_col=\"date\",\n",
    "    value_cols=\"median_listing_price\",\n",
    "    freq=\"MS\",\n",
    "    )\n",
    "    grouped_ts[state] = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a119c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_cov_ts = {}\n",
    "future_cov_ts = {}\n",
    "past_cov_cols = ['median_listing_price_mm',\n",
    "    'median_listing_price_yy', 'active_listing_count',\n",
    "    'active_listing_count_mm', 'active_listing_count_yy',\n",
    "    'median_days_on_market', 'median_days_on_market_mm',\n",
    "    'median_days_on_market_yy', 'new_listing_count', 'new_listing_count_mm',\n",
    "    'new_listing_count_yy', 'price_increased_count',\n",
    "    'price_increased_count_mm', 'price_increased_count_yy',\n",
    "    'price_increased_share', 'price_increased_share_mm',\n",
    "    'price_increased_share_yy', 'price_reduced_count',\n",
    "    'price_reduced_count_mm', 'price_reduced_count_yy',\n",
    "    'price_reduced_share', 'price_reduced_share_mm',\n",
    "    'price_reduced_share_yy', 'pending_listing_count',\n",
    "    'pending_listing_count_mm', 'pending_listing_count_yy',\n",
    "    'median_listing_price_per_square_foot',\n",
    "    'median_listing_price_per_square_foot_mm',\n",
    "    'median_listing_price_per_square_foot_yy', 'median_square_feet',\n",
    "    'median_square_feet_mm', 'median_square_feet_yy',\n",
    "    'average_listing_price', 'average_listing_price_mm',\n",
    "    'average_listing_price_yy', 'total_listing_count',\n",
    "    'total_listing_count_mm', 'total_listing_count_yy', 'pending_ratio',\n",
    "    'pending_ratio_mm', 'pending_ratio_yy']\n",
    "future_cov_cols = ['month','year']  # calendar features known ahead\n",
    "\n",
    "for state, g in df.groupby('state'):\n",
    "    # Past covariates as a multivariate TimeSeries\n",
    "    if all(c in g.columns for c in past_cov_cols):\n",
    "        past_cov_ts[state] = TimeSeries.from_dataframe(g, time_col='date', value_cols=past_cov_cols, freq='MS')\n",
    "    else:\n",
    "        past_cov_ts[state] = None\n",
    "\n",
    "    if all(c in g.columns for c in future_cov_cols):\n",
    "        future_cov_ts[state] = TimeSeries.from_dataframe(g, time_col='date', value_cols=future_cov_cols, freq='MS')\n",
    "    else:\n",
    "        future_cov_ts[state] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d5ce6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dict = {}\n",
    "ts_transformed = {}\n",
    "\n",
    "for state in grouped_ts:\n",
    "    log_transformer = InvertibleMapper(np.log1p, np.expm1)   # log1p for target, invertible\n",
    "    scaler = Scaler()\n",
    "    pipe = Pipeline([log_transformer, scaler])\n",
    "    # fit_transform expects a TimeSeries (or list); we pass the one series\n",
    "    transformed = pipe.fit_transform(grouped_ts[state])\n",
    "    pipeline_dict[state] = pipe\n",
    "    ts_transformed[state] = transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f041d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list = [ts_transformed[s] for s in ts_transformed]\n",
    "past_cov_list = [past_cov_ts[s] for s in ts_transformed]\n",
    "future_cov_list = [future_cov_ts[s] for s in ts_transformed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "394aa171",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predict = 1  # next month\n",
    "train_series = []\n",
    "val_series = []\n",
    "train_pasts = []\n",
    "val_pasts = []\n",
    "train_futures = []\n",
    "val_futures = []\n",
    "test_futures = []\n",
    "\n",
    "for s in ts_transformed:\n",
    "    ts = ts_transformed[s]\n",
    "    # if len(ts) < 24:\n",
    "    #     # skip too-short series (optional) or handle differently\n",
    "    #     continue\n",
    "    train = ts[:-n_predict]\n",
    "    val = ts[-n_predict:]  # last month\n",
    "    train_series.append(train)\n",
    "    val_series.append(val)\n",
    "    # same slicing for covariates if present\n",
    "    if past_cov_ts[s] is not None:\n",
    "        train_pasts.append(past_cov_ts[s][:-n_predict])\n",
    "        val_pasts.append(past_cov_ts[s][-n_predict:])\n",
    "    else:\n",
    "        train_pasts.append(None)\n",
    "        val_pasts.append(None)\n",
    "    if future_cov_ts[s] is not None:\n",
    "        train_futures.append(future_cov_ts[s][:-n_predict])\n",
    "        val_futures.append(future_cov_ts[s][-n_predict:])\n",
    "        test_futures.append(future_cov_ts[s])  # for final test prediction\n",
    "    else:\n",
    "        train_futures.append(None)\n",
    "        val_futures.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "87333886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "# Extend each state's future covariates separately\n",
    "for i, ts in enumerate(test_futures):\n",
    "    if ts is None:\n",
    "        continue\n",
    "    last_date = ts.end_time()\n",
    "    future_ext = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=n_predict, freq=\"MS\")\n",
    "    \n",
    "    extra_covs = pd.DataFrame({\n",
    "        \"year\": future_ext.year,\n",
    "        \"month\": future_ext.month,\n",
    "    }, index=future_ext)\n",
    "    \n",
    "    extra_covs_ts = TimeSeries.from_dataframe(extra_covs)\n",
    "    test_futures[i] = ts.append(extra_covs_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a9c4a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 5583.9434, RMSLE: 0.0110, MAE: 3986.7708, MAPE: 0.84%, R²: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\1 Disk D\\Mora Academic\\Sem 5\\Data Science and Engineering Project\\AI-ML-Services\\myenv\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [21:53:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/09/16 21:53:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGB_Darts_Model\"):\n",
    "\n",
    "    # Log model hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"lags\": 12,\n",
    "        \"lags_past_covariates\": list(range(-24, 0)),\n",
    "        \"lags_future_covariates\": list(range(1, n_predict+1)),\n",
    "        \"output_chunk_length\": n_predict,\n",
    "        \"random_state\": 42\n",
    "    })\n",
    "\n",
    "    xgb_model = XGBModel(\n",
    "        lags=12,\n",
    "        lags_past_covariates=list(range(-24, 0)),\n",
    "        lags_future_covariates=list(range(1, n_predict+1)),\n",
    "        output_chunk_length=n_predict,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(\n",
    "        series=train_series,\n",
    "        past_covariates=train_pasts,\n",
    "        future_covariates=train_futures,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    preds = xgb_model.predict(\n",
    "        n=n_predict,\n",
    "        series=train_series,\n",
    "        past_covariates=train_pasts,\n",
    "        future_covariates=test_futures\n",
    "    )\n",
    "\n",
    "    y_true, y_hat = [], []\n",
    "    for i, sname in enumerate(ts_transformed):\n",
    "        pred_ts = preds[i]\n",
    "        inv = pipeline_dict[sname].inverse_transform(pred_ts)\n",
    "        y_hat.append(inv.values()[-1].item())\n",
    "\n",
    "        true_val = val_series[i]\n",
    "        true_inv = pipeline_dict[sname].inverse_transform(true_val)\n",
    "        y_true.append(true_inv.values()[-1].item())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_hat = np.array(y_hat)\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_hat))\n",
    "    rmsle = math.sqrt(((np.log1p(np.maximum(0, y_hat)) - np.log1p(np.maximum(0, y_true)))**2).mean())\n",
    "    mae = mean_absolute_error(y_true, y_hat)\n",
    "    mape = np.mean(np.abs((y_true - y_hat) / y_true)) * 100\n",
    "    r2 = r2_score(y_true, y_hat)\n",
    "\n",
    "    print(f\"Validation RMSE: {rmse:.4f}, RMSLE: {rmsle:.4f}, \"\n",
    "          f\"MAE: {mae:.4f}, MAPE: {mape:.2f}%, R²: {r2:.4f}\")\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"RMSE\": rmse,\n",
    "        \"RMSLE\": rmsle,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "    # Log trained model\n",
    "    mlflow.xgboost.log_model(xgb_model.model, artifact_path=\"darts_xgb_model\")\n",
    "\n",
    "# End MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b6bf6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags = 12\n",
    "# lags_past_covariates = list(range(-24,0))   # previous 24 months of past covariates\n",
    "# lags_future_covariates = list(range(1, n_predict+1))  # months ahead \n",
    "\n",
    "# xgb_model = XGBModel(\n",
    "#     lags=lags,\n",
    "#     lags_past_covariates=lags_past_covariates,\n",
    "#     lags_future_covariates=lags_future_covariates,\n",
    "#     output_chunk_length=n_predict,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Fit on the training series list (global model trained across all states)\n",
    "# xgb_model.fit(series=train_series, past_covariates=train_pasts, future_covariates=train_futures,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ec67fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = xgb_model.predict(\n",
    "#     n=n_predict,\n",
    "#     series=train_series,\n",
    "#     past_covariates=train_pasts,\n",
    "#     future_covariates=test_futures  # includes July covariates\n",
    "# )\n",
    "# # preds is a list/sequence of TimeSeries (one per input series)\n",
    "# # invert transforms per state and compute metrics\n",
    "# import pandas as pd\n",
    "# y_true = []\n",
    "# y_hat = []\n",
    "\n",
    "# for i, sname in enumerate(ts_transformed):\n",
    "#     # preds[i] corresponds to series_list order; be careful with alignment\n",
    "#     pred_ts = preds[i]\n",
    "#     # invert transform using the state's pipeline\n",
    "#     inv = pipeline_dict[sname].inverse_transform(pred_ts)\n",
    "#     # extract scalar value\n",
    "#     y_hat.append(inv.values()[-1].item())   # predicted next-month price\n",
    "#     # true next-month value (from val_series)\n",
    "#     true_val = val_series[i]\n",
    "#     true_inv = pipeline_dict[sname].inverse_transform(true_val)\n",
    "#     y_true.append(true_inv.values()[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "699786d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# y_true = np.array(y_true)\n",
    "# y_hat = np.array(y_hat)\n",
    "\n",
    "# rmse = math.sqrt(mean_squared_error(y_true, y_hat))\n",
    "# rmsle = math.sqrt(((np.log1p(np.maximum(0, y_hat)) - np.log1p(np.maximum(0, y_true)))**2).mean())\n",
    "# mae = mean_absolute_error(y_true, y_hat)\n",
    "# mape = np.mean(np.abs((y_true - y_hat) / y_true)) * 100\n",
    "# r2 = r2_score(y_true, y_hat)\n",
    "\n",
    "# print(f\"Validation RMSE: {rmse:.4f}, RMSLE: {rmsle:.4f}, \"\n",
    "#       f\"MAE: {mae:.4f}, MAPE: {mape:.2f}%, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d32432",
   "metadata": {},
   "source": [
    "# Predictions on AUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4a76f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = []\n",
    "train_pasts = []\n",
    "train_futures = []\n",
    "test_futures = []\n",
    "\n",
    "for s in ts_transformed:\n",
    "    ts = ts_transformed[s]\n",
    "    train = ts\n",
    "    train_series.append(train)\n",
    "    # same slicing for covariates if present\n",
    "    if past_cov_ts[s] is not None:\n",
    "        train_pasts.append(past_cov_ts[s])\n",
    "    else:\n",
    "        train_pasts.append(None)\n",
    "    if future_cov_ts[s] is not None:\n",
    "        train_futures.append(future_cov_ts[s])\n",
    "        test_futures.append(future_cov_ts[s])\n",
    "    else:\n",
    "        train_futures.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f09ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBModel(lags=12, lags_past_covariates=[-24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1], lags_future_covariates=[1], output_chunk_length=1, output_chunk_shift=0, add_encoders=None, likelihood=None, quantiles=None, random_state=42, multi_models=True, use_static_covariates=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags = 12\n",
    "lags_past_covariates = list(range(-24,0))   # previous 24 months of past covariates\n",
    "lags_future_covariates = list(range(1, n_predict+1))  # months ahead \n",
    "\n",
    "xgb_model = XGBModel(\n",
    "    lags=lags,\n",
    "    lags_past_covariates=lags_past_covariates,\n",
    "    lags_future_covariates=lags_future_covariates,\n",
    "    output_chunk_length=n_predict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on the training series list (global model trained across all states)\n",
    "xgb_model.fit(series=train_series, past_covariates=train_pasts, future_covariates=train_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f77e862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "# Extend each state's future covariates separately\n",
    "for i, ts in enumerate(test_futures):\n",
    "    if ts is None:\n",
    "        continue\n",
    "    last_date = ts.end_time()\n",
    "    future_ext = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=n_predict, freq=\"MS\")\n",
    "    \n",
    "    extra_covs = pd.DataFrame({\n",
    "        \"year\": future_ext.year,\n",
    "        \"month\": future_ext.month,\n",
    "    }, index=future_ext)\n",
    "    \n",
    "    extra_covs_ts = TimeSeries.from_dataframe(extra_covs)\n",
    "    test_futures[i] = ts.append(extra_covs_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "85b5594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "\n",
    "# Extend each state's future covariates separately\n",
    "for i, ts in enumerate(test_futures):\n",
    "    if ts is None:\n",
    "        continue\n",
    "    last_date = ts.end_time()\n",
    "    future_ext = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=n_predict, freq=\"MS\")\n",
    "    \n",
    "    extra_covs = pd.DataFrame({\n",
    "        \"year\": future_ext.year,\n",
    "        \"month\": future_ext.month,\n",
    "    }, index=future_ext)\n",
    "    \n",
    "    extra_covs_ts = TimeSeries.from_dataframe(extra_covs)\n",
    "    test_futures[i] = ts.append(extra_covs_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9cb47463",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real = pd.read_csv(\"data\\RDC_Inventory_Core_Metrics_State.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ff03d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real = test_real.sort_values(['state']).reset_index(drop=True)\n",
    "test_real = test_real['median_listing_price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ecfee4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_model.predict(\n",
    "    n=n_predict,\n",
    "    series=train_series,\n",
    "    past_covariates=train_pasts,\n",
    "    future_covariates=test_futures  # includes July covariates\n",
    ")\n",
    "# preds is a list/sequence of TimeSeries (one per input series)\n",
    "# invert transforms per state and compute metrics\n",
    "import pandas as pd\n",
    "y_true = []\n",
    "y_hat = []\n",
    "\n",
    "for i, sname in enumerate(ts_transformed):\n",
    "    # preds[i] corresponds to series_list order; be careful with alignment\n",
    "    pred_ts = preds[i]\n",
    "    # invert transform using the state's pipeline\n",
    "    inv = pipeline_dict[sname].inverse_transform(pred_ts)\n",
    "    # extract scalar value\n",
    "    y_hat.append(inv.values()[-1].item())   # predicted next-month price\n",
    "    # true next-month value (from val_series)\n",
    "    true_val = val_series[i]\n",
    "    true_inv = pipeline_dict[sname].inverse_transform(true_val)\n",
    "    y_true.append(true_inv.values()[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9a7a2a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 5873.2905, RMSLE: 0.0121, MAE: 4070.0000, MAPE: 0.88%, R²: 0.9981\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_true = np.array(test_real)\n",
    "y_hat = np.array(y_hat)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_true, y_hat))\n",
    "rmsle = math.sqrt(((np.log1p(np.maximum(0, y_hat)) - np.log1p(np.maximum(0, y_true)))**2).mean())\n",
    "mae = mean_absolute_error(y_true, y_hat)\n",
    "mape = np.mean(np.abs((y_true - y_hat) / y_true)) * 100\n",
    "r2 = r2_score(y_true, y_hat)\n",
    "\n",
    "print(f\"Validation RMSE: {rmse:.4f}, RMSLE: {rmsle:.4f}, \"\n",
    "      f\"MAE: {mae:.4f}, MAPE: {mape:.2f}%, R²: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
